{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis,LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,precision_score,confusion_matrix,mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,RandomForestRegressor,ExtraTreesClassifier ,GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFECV,RFE,VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,train_test_split,learning_curve,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "import time\n",
    "#import scikitplot as skplt\n",
    "import itertools\n",
    "warnings.filterwarnings('ignore')\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stock_quotes.csv\")    \n",
    "X = df.iloc[:,2:].values\n",
    "y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "# for train_index, test_index in sss.split(X, df.iloc[:,1].values):\n",
    "#     #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "# columns = ['high','low','close','volume']\n",
    "# X_train=pd.DataFrame(X_train,columns=columns)\n",
    "# #print(X_train.columns)\n",
    "# #X_train.hist(figsize=(10,15))\n",
    "# X_test=pd.DataFrame(X_test,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### StandardScaler based transform\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline - comparing model accuracy using all features across classifiers \n",
    "classifiers = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(),\n",
    "#     LogisticRegression(),\n",
    "#     LinearDiscriminantAnalysis(),\n",
    "#     QuadraticDiscriminantAnalysis(),\n",
    "    GradientBoostingRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    SVR(),\n",
    "    DecisionTreeRegressor()\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "[0.9985982895721701]\n",
      "[12.129036195133269]\n",
      "[255.58146521909345]\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "[0.9968290290811399]\n",
      "[17.39091086647727]\n",
      "[578.1803270624208]\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "[0.9962145936262904]\n",
      "[18.509482172790765]\n",
      "[690.2136762586246]\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "[0.9922235212889337]\n",
      "[23.88939763849432]\n",
      "[1417.9275432064373]\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "[0.26980760904252654]\n",
      "[265.5533541805311]\n",
      "[133139.93922531742]\n",
      "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best')\n",
      "[0.9960657871096125]\n",
      "[21.51767060250948]\n",
      "[717.3463755748194]\n"
     ]
    }
   ],
   "source": [
    "r2score = []\n",
    "MAE = []\n",
    "MSE = []\n",
    "MAPE = []\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf)\n",
    "    r2score.append(clf.score(X_test,y_test))\n",
    "    MAE.append(mean_absolute_error(y_test,y_pred))\n",
    "    MSE.append(mean_squared_error(y_test,y_pred))\n",
    "#     print(MAPE.append(mean_absolute_percentage_error(y_test,y_pred)))\n",
    "    print(r2score)\n",
    "    print(MAE)\n",
    "    print(MSE)\n",
    "    r2score.clear()\n",
    "    MAE.clear()\n",
    "    MSE.clear()\n",
    "#     MAPE.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "[0.9985982895721702]\n",
      "[12.129036195133269]\n",
      "[255.58146521909345]\n",
      "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False)\n",
      "[0.9968781200450804]\n",
      "[17.107931253452506]\n",
      "[569.2293053365232]\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "[0.9965060720309787]\n",
      "[18.224306151215476]\n",
      "[637.0668377455422]\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "[0.9922235212889335]\n",
      "[23.88939763849432]\n",
      "[1417.9275432064373]\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "[0.26980760904252654]\n",
      "[265.5533541805311]\n",
      "[133139.93922531742]\n",
      "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
      "                      max_features=None, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                      random_state=None, splitter='best')\n",
      "[0.9947008061663875]\n",
      "[23.853530421401523]\n",
      "[966.2307546442813]\n"
     ]
    }
   ],
   "source": [
    "r2score = []\n",
    "MAE = []\n",
    "MSE = []\n",
    "MAPE = []\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf)\n",
    "    r2score.append(r2_score(y_test,y_pred))\n",
    "    MAE.append(mean_absolute_error(y_test,y_pred))\n",
    "    MSE.append(mean_squared_error(y_test,y_pred))\n",
    "#     print(MAPE.append(mean_absolute_percentage_error(y_test,y_pred)))\n",
    "    print(r2score)\n",
    "    print(MAE)\n",
    "    print(MSE)\n",
    "    r2score.clear()\n",
    "    MAE.clear()\n",
    "    MSE.clear()\n",
    "#     MAPE.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Naive Train Accuracy\n",
    "# algo = []\n",
    "# scores = []\n",
    "# for clf in classifiers:\n",
    "#     breakpoint()\n",
    "#     algo.append(clf.__class__.__name__)\n",
    "#     scores.append(cross_val_score(clf,X_train,y_train, cv=5,scoring='accuracy').mean())\n",
    "# warnings.filterwarnings('ignore')\n",
    "# Naivescore_df_Train = pd.DataFrame({'Algorithm': algo, 'Score': scores}).set_index('Algorithm')\n",
    "\n",
    "# print(\"Train\",Naivescore_df_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2027.29591404 3049.87199614 2165.05980566 2632.15214275 3146.96046484\n 2108.98417385 2650.32638939 2106.23104946 3108.18967111 2242.1545871\n 2121.52975691 2196.07686535 2736.26758905 2901.58006782 2657.30674372\n 2183.97253207 1907.18125657 2011.75124531 2047.52740069 2133.42411453\n 1994.52496685 2310.14607966 2257.89209957 2173.05810358 2082.31302498\n 2307.71015313 2719.30474285 2095.90519547 3182.62511821 2032.42305373\n 2074.25193613 3251.60990391 2131.33769551 2480.86304225 2424.28813905\n 2216.32577114 1878.59446646 3084.42447495 2201.79203583 2159.47164649\n 3064.44932443 2221.48783952 2121.54307202 2050.75859155 1983.36441804\n 2169.65183329 2117.81797463 2776.17341457 1720.14325667 2819.08545686\n 3108.96458319 2075.68412466 2248.03051069 2268.19385159 3250.24968481\n 1681.46795164 2097.45499062 3146.44220943 2239.02438278 1962.61544459\n 2178.52916454 2933.90229785 3174.33500708 2276.50403339 2181.86748223\n 2216.0276963  3206.04737126 1952.28529238 2141.45867307 2062.21855111\n 2101.69805294 2057.98385983 2309.79193861 2066.00787097 2256.86107065\n 2031.93213898 2189.79291795 1925.30931806 3025.72697293 2110.5536256\n 2844.96162605 2691.04291511 2196.64318022 2045.21066263 3047.5690174\n 2043.4333614  2938.1530447  2059.17983187 1791.50737608 3231.82223041\n 2838.30157488 3094.93297288 2042.49328653 2362.49673085 2010.5992758\n 2208.5012315  2264.5273194  3068.35452111 1842.43381176].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9cbec055a0e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#y_pred=label_encoder.fit_transform(y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mScore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Predicted\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Actual\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#warnings.filterwarnings('ignore')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mNaivescore_df_Test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Algorithm'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Algorithm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_regression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m         \u001b[1;31m# XXX: Remove the check in 0.23\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \"\"\"\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    209\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2027.29591404 3049.87199614 2165.05980566 2632.15214275 3146.96046484\n 2108.98417385 2650.32638939 2106.23104946 3108.18967111 2242.1545871\n 2121.52975691 2196.07686535 2736.26758905 2901.58006782 2657.30674372\n 2183.97253207 1907.18125657 2011.75124531 2047.52740069 2133.42411453\n 1994.52496685 2310.14607966 2257.89209957 2173.05810358 2082.31302498\n 2307.71015313 2719.30474285 2095.90519547 3182.62511821 2032.42305373\n 2074.25193613 3251.60990391 2131.33769551 2480.86304225 2424.28813905\n 2216.32577114 1878.59446646 3084.42447495 2201.79203583 2159.47164649\n 3064.44932443 2221.48783952 2121.54307202 2050.75859155 1983.36441804\n 2169.65183329 2117.81797463 2776.17341457 1720.14325667 2819.08545686\n 3108.96458319 2075.68412466 2248.03051069 2268.19385159 3250.24968481\n 1681.46795164 2097.45499062 3146.44220943 2239.02438278 1962.61544459\n 2178.52916454 2933.90229785 3174.33500708 2276.50403339 2181.86748223\n 2216.0276963  3206.04737126 1952.28529238 2141.45867307 2062.21855111\n 2101.69805294 2057.98385983 2309.79193861 2066.00787097 2256.86107065\n 2031.93213898 2189.79291795 1925.30931806 3025.72697293 2110.5536256\n 2844.96162605 2691.04291511 2196.64318022 2045.21066263 3047.5690174\n 2043.4333614  2938.1530447  2059.17983187 1791.50737608 3231.82223041\n 2838.30157488 3094.93297288 2042.49328653 2362.49673085 2010.5992758\n 2208.5012315  2264.5273194  3068.35452111 1842.43381176].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Naive Test Accuracy\n",
    "algo = []\n",
    "# scores = [[]]\n",
    "Score={}\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    algo.append(clf.__class__.__name__)\n",
    "    #y_pred=label_encoder.fit_transform(y_pred)\n",
    "    Score[i]=pd.DataFrame({\"Predicted\":y_pred,\"Actual\":y_test})\n",
    "    scores = clf.score(y_pred, y_test)\n",
    "#warnings.filterwarnings('ignore')\n",
    "Naivescore_df_Test  = pd.DataFrame({'Algorithm': algo, 'Score': scores}).set_index('Algorithm')\n",
    "\n",
    "print(\"Test\",Naivescore_df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
